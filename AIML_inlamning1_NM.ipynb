{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfH6QqjKiDbtEjANq2HoAF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NickMattiss/AIML_inlamning1/blob/main/AIML_inlamning1_NM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcNgWLnsGGZJ"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "Th0LWMkGGRi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"aiml_inlamning1_wandb\")\n",
        "# wandb.login()"
      ],
      "metadata": {
        "id": "95kV7COmGRmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install numpy tensorflow\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "nc2fuR2PGRp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the data\n",
        "\n",
        "# Prepare & Clean the data\n",
        "\n",
        "# Split the data \n",
        "\n",
        "def get_fashion_mnist_dataset():\n",
        "    # Load the data and split it between train and test sets\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "    # Scale images to the [0, 1] range\n",
        "    x_train = x_train.astype(\"float32\") / 255\n",
        "    x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "    # Make sure images have shape (28, 28, 1)\n",
        "    x_train = np.expand_dims(x_train, -1)\n",
        "    x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    num_classes = 10\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "metadata": {
        "id": "r8h51wi-GRtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "batch_size = 128\n",
        "epochs = 1"
      ],
      "metadata": {
        "id": "PO0vPjStGRxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the training data\n",
        "x_train, y_train = get_fashion_mnist_dataset()[0]"
      ],
      "metadata": {
        "id": "R-ui_WF9GRzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Convolutional Neural Network that expects a 28x28 pixel image with 1 color chanel (gray) as input\n",
        "model = create_cnn((28, 28, 1), 10)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, batch_size=batch_size,\n",
        "          epochs=epochs, validation_split=0.1,\n",
        "          callbacks=[wandb.keras.WandbCallback()])"
      ],
      "metadata": {
        "id": "RzeuKJKNGR2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPROCESS WITH WANDB"
      ],
      "metadata": {
        "id": "dDZZyUIVGR5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install numpy tensorflow wandb\n",
        "\n",
        "import wandb\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4k9vBSAPGSCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "date_and_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "wandb_run = wandb.init(\n",
        "    project=\"aiml_inlamning1_wandb\",\n",
        "    name=f\"preprocessing {date_and_time}\"\n",
        ")"
      ],
      "metadata": {
        "id": "9hLBPHT5GSFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "J8wENEB4GSIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define histograms\n",
        "\n",
        "def log_bar(x, y, title, x_name=\"x\", y_name=\"y\", keep_order=False):\n",
        "    if keep_order:\n",
        "        x = [f\"{idx}: {x_}\" for idx, x_ in enumerate(x)] # Make sure alphabetical sorting works\n",
        "    table = wandb.Table(\n",
        "        data=[[x, y] for x, y in zip(x, y)],\n",
        "        columns=[x_name, y_name]\n",
        "    )\n",
        "    wandb.log({title: wandb.plot.bar(table, x_name, y_name, title=title)})\n",
        "\n",
        "\n",
        "def create_histogram(data, min_value=None, max_value=None, bins=10):\n",
        "    if min_value is None:\n",
        "        min_value = data.min()\n",
        "    if max_value is None:\n",
        "        max_value = data.max()\n",
        "\n",
        "    if isinstance(bins, int):\n",
        "        bin_edges = np.linspace(min_value, max_value, num=bins)\n",
        "    else:\n",
        "        bin_edges = bins\n",
        "        \n",
        "    numbers, _ = np.histogram(data, bins=bin_edges)\n",
        "    bin_names = [f\"{lower:.1f}-{upper:.1f}\" for lower, upper in zip(bin_edges[:-1], bin_edges[1:])]\n",
        "\n",
        "    return bin_names, numbers"
      ],
      "metadata": {
        "id": "Gr-7RTMZGSLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize labels\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "num_images_per_label = Counter(y_train)\n",
        "x, num_images = zip(*((str(x_), num_) for x_, num_ in sorted(num_images_per_label.items())))\n",
        "log_bar(x, num_images, \"Labels in training data\", x_name=\"Label\", y_name=\"# images\")\n",
        "\n",
        "num_images_per_label = Counter(y_test)\n",
        "x, num_images = zip(*((str(x_), num_) for x_, num_ in sorted(num_images_per_label.items())))\n",
        "log_bar(x, num_images, \"Labels in test data\", x_name=\"Label\", y_name=\"# images\")"
      ],
      "metadata": {
        "id": "hGA2yWX9GSOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training data\n",
        "i = 0\n",
        "print(f\"Sample {i} is number {y_train[i]}\")\n",
        "plt.imshow(x_train[0])\n",
        "\n",
        "image = wandb.Image(x_train[0], caption=f\"Training sample {i} is a {y_train[i]}\")\n",
        "wandb.log({\"Example training image\": image})"
      ],
      "metadata": {
        "id": "2e5f9SFIGSSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log the datasets minimum and maximum intensities and datatype to the WandB summary\n",
        "min_value = min(x_train.min(), x_test.min())\n",
        "max_value = max(x_train.max(), x_test.max())\n",
        "wandb_run.summary[\"raw\"] = {\"min\": min_value, \"max\": max_value, \"dtype\": str(x_train.dtype)}\n",
        "\n",
        "# Create a new histogram of the image pixels intensities\n",
        "bin_names, train_hist = create_histogram(x_train)\n",
        "log_bar(bin_names, train_hist, \"Raw training data\", x_name=\"bin\", y_name=\"# pixels\", keep_order=True)"
      ],
      "metadata": {
        "id": "PwENf8hwGSU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a heatmap over all active pixels from all frames\n",
        "heatmap = np.mean(x_train, axis=0)\n",
        "plt.imshow(heatmap)\n",
        "wandb.log({\"Heatmap of training images\": wandb.Image(np.expand_dims(heatmap, axis=2), caption=\"The mean of all images in the training set\")})\n",
        "\n",
        "# Log a histogram of the average value for each pixel through out the\n",
        "# training dataset. This shows us how many of the pixels that are\n",
        "# always zero in all frames.\n",
        "bin_names, heatmap_hist = create_histogram(heatmap.flatten(), bins=[0, 1, 10, 30, 100, 255])\n",
        "log_bar(bin_names, heatmap_hist, \"Average value per pixel in training data\", x_name=\"bin\", y_name=\"# pixels\", keep_order=True)"
      ],
      "metadata": {
        "id": "HsosbXeyGSYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "# Normalize the values to the range -1...1\n",
        "x_train_norm = x_train / 128 - 1\n",
        "x_test_norm = x_test / 128 - 1"
      ],
      "metadata": {
        "id": "uHj-5LQ9Gwor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new histogram of the modified values\n",
        "min_value = min(x_train_norm.min(), x_test_norm.min())\n",
        "max_value = max(x_train_norm.max(), x_test_norm.max())\n",
        "wandb_run.summary[\"preprocessed\"] = {\"min\": min_value, \"max\": max_value, \"dtype\": str(x_train_norm.dtype)}\n",
        "\n",
        "bin_names, train_hist = create_histogram(x_train_norm)\n",
        "log_bar(bin_names, train_hist, \"Preprocessed training data\", x_name=\"bin\", y_name=\"# pixels\", keep_order=True)"
      ],
      "metadata": {
        "id": "E84Y6CZdGwvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "print(f\"Sample {i} is number {y_train[i]}\")\n",
        "plt.imshow(x_train_norm[0])\n",
        "\n",
        "image = wandb.Image(x_train_norm[0], caption=f\"Training sample {i} is a {y_train[i]}\")\n",
        "wandb.log({\"Example training image (preprocessed)\": image})"
      ],
      "metadata": {
        "id": "Z_jxvc0aGwzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample test data\n",
        "num_images_per_label = Counter(y_test)\n",
        "min_number_of_labels = min(num_images_per_label.values())\n",
        "\n",
        "indexes_to_keep = []\n",
        "for label in num_images_per_label.keys():\n",
        "  indexes_to_keep.extend(\n",
        "      np.random.choice(\n",
        "          np.where(y_test == label)[0],\n",
        "          size=min_number_of_labels,\n",
        "          replace=False\n",
        "      ).tolist()\n",
        "  )\n",
        "\n",
        "np.random.shuffle(indexes_to_keep)\n",
        "x_test_norm_subsamp = x_test_norm[indexes_to_keep]\n",
        "y_test_subsamp = y_test[indexes_to_keep]"
      ],
      "metadata": {
        "id": "aYVQN0ylGw2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_norm_subsamp.shape"
      ],
      "metadata": {
        "id": "ZkAfa5WUG6dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that the labels and images are still in sync\n",
        "print(f\"This should be a {y_test_subsamp[0]}\")\n",
        "plt.imshow(x_test_norm_subsamp[0])"
      ],
      "metadata": {
        "id": "ku22ogIYG6g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log the new distribution\n",
        "num_images_per_label = Counter(y_test_subsamp)\n",
        "labels_, num_images = zip(*((str(label), number) for label, number in sorted(num_images_per_label.items())))\n",
        "log_bar(labels_, num_images, \"Labels in test data (subsampled)\", x_name=\"Label\", y_name=\"# images\")"
      ],
      "metadata": {
        "id": "S5RHHy_yG6lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mP8RstutG6pr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}